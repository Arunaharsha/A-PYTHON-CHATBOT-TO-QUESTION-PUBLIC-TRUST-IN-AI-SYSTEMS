This project presents the construction, codebase and testing of a conversational agent that was intentionally designed to challenge and debate the question of trust in the artificial intelligence (AI) systems. It was believed that because of the active spread of automation into the services that people engage in by AI, the contradiction between the mentioned intentions of the ethical approach of AI implementation and its actual implementation are highly visible in a contrasting way. The system was modeled in a way that the users may engage in a discourse of compassion, situational context in the topics of AI ethics, audibility, equitability, and privacy. The chatbot is based on a retrieval-augmented generation (RAG) model where Google Gemini, a massive language model, is trained on 2 curated FAISS-based vector stores, to store AI ethics resources (AI Ethics Vector Store) and chat examples related to trust (Trustful Chat Vector Store). A trust classification module, beginning with a lightweight sentiment and keyword solution then graduating into a machine learning based classifier that dynamically annotates all user messages as being of low, neutral or high trust allowing adaptive conversational strategies. The architecture is also informed with data via the secure Flask API and the SQLite database which ensures that it is anonymised, permitted, and compliant with the ethical standards. The controlled user studies were performed on fifty participants, which reversed quantitative and qualitative evidence of the influence. The findings suggest that the mean trust score is significantly higher with a trust-conscious chatbot of +0.9 points (p < 0.05), and the augmented trust-conscious chatbot with a higher user- and system-reported trust and relevance and general transparency than the baseline factual chatbot. The findings affirm the usefulness of trust-informed conversational AI as a device of engaging citizens and offers a framework that could be expanded and ethically sustained as prototypes of future implementations in the formation of knowledgeable, assured, and critically involved encounters between citizens and AI platforms.
